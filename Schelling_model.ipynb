{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JiaXiao-Peter/peter.github.io/blob/main/Schelling_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a69a9211",
      "metadata": {
        "id": "a69a9211"
      },
      "source": [
        "# **Build Your Own LLM Society**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 1: Test the API Connection**\n",
        "\n",
        "First, let's make sure the API works. This is the last code from our previous class, establishing the basic API connection."
      ],
      "metadata": {
        "id": "m3S5W00f0ZEG"
      },
      "id": "m3S5W00f0ZEG"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "# Connect to Shubiaobiao API\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.shubiaobiao.cn/v1/\",\n",
        "    api_key=\"sk-7MPDKIdGJngMDr5i5a15907dF4Ec4c8294AfB58dAe43Db5e\",\n",
        ")\n",
        "\n",
        "# Test a simple conversation\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Introduce yourself in one sentence\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"âœ… API connected successfully!\")\n",
        "print(\"Assistant reply:\", completion.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "i-GoqOBB0fz2"
      },
      "id": "i-GoqOBB0fz2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Explanation:***\n",
        "We reuse the exact same API-setup cell from the previous lesson. Once it runs without errors, we are ready to embed LLM calls into the Schelling simulation."
      ],
      "metadata": {
        "id": "s_7Ra2DU1-H0"
      },
      "id": "s_7Ra2DU1-H0"
    },
    {
      "cell_type": "markdown",
      "id": "21832832",
      "metadata": {
        "id": "21832832"
      },
      "source": [
        "### **Cell 2: Import the modular Schelling framework**\n",
        "\n",
        "We directly reuse the modular scaffold built in Lab 2, which already decomposes the Schelling model into plug-and-play components. This lets us swap in a LLM-based decision rule without touching the rest of the pipeline.\n",
        "\n",
        "The same `schelling/` package from Lab 2 is reused unchanged:\n",
        "\n",
        "- `initialization.py` â€“ how the city is seeded  \n",
        "- `agent_selector.py` â€“ which agent gets a turn  \n",
        "- `target_selector.py` â€“ which vacant cell is shortlisted  \n",
        "- `move_acceptor.py` â€“ **this is our plug-in point**; the original greedy rule will be replaced by an LLM call inside the notebook  \n",
        "- `stop_criterion.py` â€“ when to halt  \n",
        "- `utils.py` â€“ plotting & utility helpers  \n",
        "\n",
        "None of the .py files are modified. We simply import the existing package to show how easily an external decision layer (LLM) can be plugged in."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys, os\n",
        "\n",
        "project_root = '/content/drive/MyDrive/Schelling-simulation-Lab5'\n",
        "sys.path.append(project_root)\n",
        "\n",
        "import types, importlib\n",
        "import sys as _sys\n",
        "_sys.modules['imp'] = types.SimpleNamespace(reload=importlib.reload)\n",
        "# -------------------------------------------\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "print(\"On sys.path:\", project_root in sys.path)\n",
        "print(\"Dir listing:\", os.listdir(project_root))\n",
        "\n",
        "from schelling import *\n",
        "import numpy as np\n",
        "print(\"âœ… Schelling framework imported successfully!\")\n"
      ],
      "metadata": {
        "id": "typRTdzA2eBf"
      },
      "id": "typRTdzA2eBf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 3: Initialise Baseline**\n",
        "\n",
        "We keep the original Lab-2 template intact and simply **swap the greedy acceptance rule** for an LLM-based decision function.  \n",
        "This version still uses:\n",
        "\n",
        "- Random initialization of agents\n",
        "- Random agent & target selection\n",
        "- Fixed-step stop criterion\n",
        "\n",
        "***Note:*** the move choice is now made by prompting an LLM, giving agents **memory and reasoning** while preserving the familiar data structures and control flow."
      ],
      "metadata": {
        "id": "Q0iY_r4z92TT"
      },
      "id": "Q0iY_r4z92TT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc683e26",
      "metadata": {
        "id": "cc683e26"
      },
      "outputs": [],
      "source": [
        "# === Parameters ===\n",
        "Q = 16        # number of neighbourhoods\n",
        "H = 10       # capacity of each neighbourhood\n",
        "rho0 = 0.5   # initial global density\n",
        "max_steps = 20  # short run for demo because LLM calls cost time\n",
        "memory_window = 3  # NEW: how many recent decisions the agent remembers\n",
        "\n",
        "# === Initialise the city ===\n",
        "occupied = initialization.init_random(Q, H, rho0)\n",
        "print(f\"Initial state: total agents {np.sum(occupied)}, mean density {np.mean(occupied/H):.2f}\")\n",
        "\n",
        "# === Visualise initial state ===\n",
        "utils.plot_density_heatmap(4, 4, occupied / H, title='Initial density heat-map', xlabel='', ylabel='')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 4: Implement Memory Mechanism**\n",
        "\n",
        "This is a simple memory scheme. In a full model each agent could carry its own memory; here we use one shared, time-ordered list to give the LLM a sense of recent collective experience."
      ],
      "metadata": {
        "id": "EU3AwcixBzei"
      },
      "id": "EU3AwcixBzei"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "agent_memory = []  # global chronological memory list\n",
        "\n",
        "# Format the latest memories into a string to be inserted into the LLM prompt.\n",
        "def format_memory_for_prompt(memory_list, window_size):\n",
        "    if not memory_list or window_size == 0:\n",
        "        return \"No historical records.\"\n",
        "\n",
        "    recent = memory_list[-window_size:]\n",
        "    prompt_segment = \"\"\n",
        "    for i, rec in enumerate(recent, 1):\n",
        "        prompt_segment += (f\"Memory {i}: at step {rec['step']} you were in neighbourhood \"\n",
        "                          f\"with density {rec['from_density']:.2f} (utility {rec['from_utility']:.2f}) \"\n",
        "                          f\"to density {rec['to_density']:.2f} (utility {rec['to_utility']:.2f}), \"\n",
        "                          f\"decision='{rec['decision']}', reason='{rec['reasoning']}'.\\n\")\n",
        "    return prompt_segment\n",
        "print(\"âœ… Memory mechanism initialised\")\n"
      ],
      "metadata": {
        "id": "5PdMW2uQBx6T"
      },
      "id": "5PdMW2uQBx6T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 5: Define the Core LLM Decision Function**\n",
        "\n",
        "Here we query the LLM to decide whether to move. This is the heart of the LLM-enhanced simulation.\n",
        "\n",
        "**Parameters:**\n",
        "- `from_block`, `to_block`: indices of origin and destination neighbourhoods\n",
        "- `occupied`: current occupancy counts per block\n",
        "- `H`: capacity of each block\n",
        "- `utility_fn`: utility function `u(density)`\n",
        "- `memory_list`: historical decision memory\n",
        "- `window_size`: how many recent memories to include\n",
        "- `client`: OpenAI client instance\n",
        "\n",
        "**Returns:**\n",
        "- `decision` (bool): `True` if LLM advises moving, `False` otherwise\n",
        "- `reasoning` (str): LLM's one-sentence justification\n",
        "- `from_density`, `to_density`, `from_utility`, `to_utility`: computed values\n",
        "\n",
        "This is the simulation's \"brain\". We explicitly ask the LLM for JSON and add error-handling. `temperature=0.3` keeps decisions consistent."
      ],
      "metadata": {
        "id": "zKST_ZPWDW7D"
      },
      "id": "zKST_ZPWDW7D"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def call_llm_for_move_decision(from_block, to_block, occupied, H, utility_fn,\n",
        "                               memory_list, window_size, client):\n",
        "\n",
        "    # Compute current and prospective densities and utilities\n",
        "    from_density = occupied[from_block] / H\n",
        "    to_density = (occupied[to_block] + 1) / H   # density after the agent arrives\n",
        "    from_utility = utility_fn(from_density)\n",
        "    to_utility = utility_fn(to_density)\n",
        "\n",
        "    # Build prompt: role + context + memory + output-format instruction\n",
        "    system_prompt = (\"You are an agent living in a city. \"\n",
        "                     \"Decide whether to move based on the current environment and your memories.\")\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "You currently live in neighbourhood {from_block} (density {from_density:.2f}, utility {from_utility:.2f}).\n",
        "You are considering moving to neighbourhood {to_block} (density after you arrive {to_density:.2f}, expected utility {to_utility:.2f}).\n",
        "\n",
        "Your memory window (last {window_size} relevant decisions) is:\n",
        "{format_memory_for_prompt(memory_list, window_size)}\n",
        "\n",
        "Make a choice. You prefer higher utility but can also learn from history.\n",
        "**Important**: Reply ONLY a plain JSON object, no Markdown fences, no extra text:\n",
        "{{\"decision\": \"move\" or \"stay\", \"reasoning\": \"brief one-sentence reason\"}}\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
        "                      {\"role\": \"user\", \"content\": user_prompt}],\n",
        "            temperature=0.3   # lower temperature for more consistent decisions\n",
        "        )\n",
        "\n",
        "        llm_output = response.choices[0].message.content.strip()\n",
        "        llm_output = re.sub(r'```json|```', '', llm_output).strip()   # delete Markdown  fence\n",
        "        parsed = json.loads(llm_output)\n",
        "\n",
        "        decision = parsed.get(\"decision\", \"stay\") == \"move\"\n",
        "        reasoning = parsed.get(\"reasoning\", \"no clear reason\")\n",
        "\n",
        "        return decision, reasoning, from_density, to_density, from_utility, to_utility\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"âš ï¸ JSON decode failed: {e}. LLM output: {llm_output[:100]}...\")\n",
        "        return False, \"JSON decode failed\", from_density, to_density, from_utility, to_utility\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ API call failed: {e}\")\n",
        "        return False, \"API call failed\", from_density, to_density, from_utility, to_utility\n",
        "\n",
        "print(\"âœ… LLM decision function defined\")\n"
      ],
      "metadata": {
        "id": "S7rjhhooDSiU"
      },
      "id": "S7rjhhooDSiU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 6: Main Simulation Loop**\n",
        "\n",
        "This cell demonstrates the retrofit process. The key change is replacing the line `if move_acceptor.accept_if_personal_utility_improves(...):` with an LLM function call and memory management, showcasing the power of modular design.\n"
      ],
      "metadata": {
        "id": "qOvOPa6uMNo1"
      },
      "id": "qOvOPa6uMNo1"
    },
    {
      "cell_type": "code",
      "source": [
        "# === ORIGINAL Lab 2 Baseline loop (commented out) ===\n",
        "\n",
        "# step = 0\n",
        "# while True:\n",
        "#     # Stopping criterion\n",
        "#     if stop_criterion.stop_after_fixed_steps(step, max_steps):\n",
        "#         print(f\"Stopped at step {step}\")\n",
        "#         break\n",
        "\n",
        "#     # 1. Select an agent block (weighted by number of agents)\n",
        "#     from_block = agent_selector.select_agent_random(occupied)\n",
        "\n",
        "#     # 2. Select a target block (must have space)\n",
        "#     to_block = target_selector.select_target_random_cell(occupied, H)\n",
        "\n",
        "#     # 3. Check if move is accepted (Î”u > 0)\n",
        "#     if move_acceptor.accept_if_personal_utility_improves(occupied[from_block] / H, (occupied[to_block] + 1) / H, utils.triangle_utility):\n",
        "#         occupied[from_block] -= 1\n",
        "#         occupied[to_block] += 1\n",
        "#     step += 1"
      ],
      "metadata": {
        "id": "XhCkxQrJMiaA"
      },
      "id": "XhCkxQrJMiaA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# === Simulation Main Loop ===\n",
        "print(\"Starting LLM-driven social simulation...\")\n",
        "initial_state_snapshot = occupied.copy()\n",
        "\n",
        "step = 0\n",
        "decision_log = []  # store every decision for later analysis\n",
        "\n",
        "while True:\n",
        "    # stopping criterion\n",
        "    if stop_criterion.stop_after_fixed_steps(step, max_steps):\n",
        "        print(f\"\\nâœ… LLM simulation stopped at step {step}\")\n",
        "        break\n",
        "\n",
        "    # 1. select an agent\n",
        "    from_block = agent_selector.select_agent_random(occupied)\n",
        "\n",
        "    # 2. select a target neighbourhood\n",
        "    to_block = target_selector.select_target_random_cell(occupied, H)\n",
        "\n",
        "    # 3. LLM decision: call the LLM to decide whether to move (core change)\n",
        "    #    we replace the simple utility comparison with LLM reasoning\n",
        "    decision, reasoning, from_d, to_d, from_u, to_u = call_llm_for_move_decision(\n",
        "        from_block, to_block, occupied, H, utils.triangle_utility,\n",
        "        agent_memory, memory_window, client\n",
        "    )\n",
        "\n",
        "    # if LLM decides to move, update state\n",
        "    if decision:\n",
        "        occupied[from_block] -= 1\n",
        "        occupied[to_block] += 1\n",
        "        move_str = \"âœ…MOVED\"\n",
        "    else:\n",
        "        move_str = \"âŒSTAYED\"\n",
        "\n",
        "    # record this decision to memory (keep window size)\n",
        "    agent_memory.append({\n",
        "        'step': step,\n",
        "        'from_block': from_block,\n",
        "        'to_block': to_block,\n",
        "        'from_density': from_d,\n",
        "        'to_density': to_d,\n",
        "        'from_utility': from_u,\n",
        "        'to_utility': to_u,\n",
        "        'decision': 'move' if decision else 'stay',\n",
        "        'reasoning': reasoning\n",
        "    })\n",
        "    if len(agent_memory) > memory_window * 10:  # cap total memory to avoid unbounded growth\n",
        "        agent_memory.pop(0)\n",
        "\n",
        "    # append to analysis log\n",
        "    decision_log.append({'step': step, 'decision': decision, 'reasoning': reasoning})\n",
        "\n",
        "    # print progress & sample decision (every 500 steps to limit output)\n",
        "    print(f\" step {step:5d} | Block {from_block} â†’ {to_block} {move_str} | reason: {reasoning}\")\n",
        "    step += 1\n",
        "\n",
        "print(\"Simulation finished!\")"
      ],
      "metadata": {
        "id": "9hREf1ClJAmJ"
      },
      "id": "9hREf1ClJAmJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 7: Visualise Final State**"
      ],
      "metadata": {
        "id": "L2u62kz6P5qA"
      },
      "id": "L2u62kz6P5qA"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot final-density heat map\n",
        "utils.plot_density_heatmap(4, 4, occupied / H,\n",
        "                           title=f'Final density heat-map', xlabel='', ylabel='')\n",
        "\n",
        "# Compute and print some statistics\n",
        "final_utilities = utils.triangle_utility(occupied / H)\n",
        "print(\"\\nSimulation summary:\")\n",
        "print(f\"  Final mean density: {np.mean(occupied/H):.3f}\")\n",
        "print(f\"  Final mean utility: {np.mean(final_utilities):.3f}\")\n",
        "print(f\"  Total decisions logged: {len(decision_log)}\")\n"
      ],
      "metadata": {
        "id": "Tno3Aw8IQEl7"
      },
      "id": "Tno3Aw8IQEl7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 8  Snapshot: From Initial to Final**\n",
        "\n",
        "| What you see | Why it matters |\n",
        "|--------------|----------------|\n",
        "| **Density heat-maps** (top row) | Instant colour check on **where people ended up**. Brighter = more crowded. Compare left â†’ right to spot segregation or mixing. |\n",
        "| **Utility heat-maps** (bottom row) | **Individual satisfaction** in each block (0-1 scale). Greener = happier. LLM choices should push blocks toward greener shades **if** utility really guides them. |\n",
        "| **Global utility** printed below | Weighted sum (âˆ‘ density Ã— utility). Gives **one-line welfare summary** of the whole city. â†‘ means LLM decisions collectively raised well-being; â†“ means they didnâ€™t. |\n",
        "\n",
        "Use this cell to **eyeball** whether your prompt / temperature / memory_window is producing:\n",
        "- more integrated (uniform red) or segregated (hot-spots) layouts,\n",
        "- higher average utility,\n",
        "- or simply different global welfare."
      ],
      "metadata": {
        "id": "_5dZkX8fYl4J"
      },
      "id": "_5dZkX8fYl4J"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----------  Compute statistics ----------\n",
        "initial_util = utils.triangle_utility(initial_state_snapshot / H)\n",
        "final_dens   = occupied\n",
        "final_util   = utils.triangle_utility(final_dens / H)\n",
        "delta_util   = final_util - initial_util\n",
        "\n",
        "move_ratio   = sum(d['decision'] for d in decision_log) / len(decision_log)\n",
        "mean_improve = np.nanmean(delta_util)\n",
        "\n",
        "# ----------  Plotting ----------\n",
        "rows = cols = int(np.sqrt(Q))\n",
        "figsize = (cols*1.8, rows*1.8)\n",
        "fig, ax = plt.subplots(2, 2, figsize=figsize, dpi=100)\n",
        "fig.suptitle(f'Initial vs Final ({max_steps} steps)', fontsize=10)\n",
        "\n",
        "def draw_heatmap(ax, data, title, cmap, vmin, vmax, fmt='.2f'):\n",
        "    \"\"\"helper: small heat-map with text annotation\"\"\"\n",
        "    im = ax.imshow(data.reshape(rows, cols), cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "    ax.set_title(title, fontsize=9)\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            ax.text(j, i, f'{data.reshape(rows, cols)[i,j]:{fmt}}',\n",
        "                    ha='center', va='center', color='black', fontsize=8)\n",
        "    return im\n",
        "\n",
        "# sub-plots\n",
        "im0 = draw_heatmap(ax[0,0], initial_state_snapshot/H, 'Initial Density',  'Reds',   0, 1)\n",
        "im1 = draw_heatmap(ax[0,1], final_dens/H,   'Final Density',    'Reds',   0, 1)\n",
        "im2 = draw_heatmap(ax[1,0], initial_util, 'Initial Personal Utility',\n",
        "                   cmap='Blues', vmin=0, vmax=1)\n",
        "im3 = draw_heatmap(ax[1,1], final_util, 'Final Personal Utility',\n",
        "                   cmap='Blues', vmin=0, vmax=1)\n",
        "\n",
        "for im, axi in zip([im0, im1], ax[0,:]): plt.colorbar(im, ax=axi, shrink=0.6, pad=0.02)\n",
        "for im, axi in zip([im2, im3], ax[1,:]): plt.colorbar(im, ax=axi, shrink=0.6, pad=0.02)\n",
        "\n",
        "plt.tight_layout(pad=0.8)\n",
        "plt.show()\n",
        "\n",
        "# ----------  Global utility ----------\n",
        "global_initial = np.sum(initial_state_snapshot / H * initial_util)\n",
        "global_final   = np.sum(final_dens / H * final_util)\n",
        "print(f\"Global utility  Initial {global_initial:.3f}  â†’  Final {global_final:.3f}  \"\n",
        "      f\"({'â†‘' if global_final > global_initial else 'â†“' if global_final < global_initial else 'â†’'})\")\n"
      ],
      "metadata": {
        "id": "jYLUdetFQ_s6"
      },
      "id": "jYLUdetFQ_s6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ðŸŽ¯Core Takeaways of Lab5:**\n",
        "\n",
        "1. **Modular Reusability**: No need to modify the original framework; introducing the LLM is achieved by replacing the decision function.\n",
        "2. **Memory Mechanism**: Adds short-term memory to the agents, making their decisions historically dependent.\n",
        "3. **Structured Interaction**: Uses JSON format to standardize LLM output, facilitating program parsing.\n",
        "4. **Explainability**: The \"reasoning\" provided by the LLM makes agent behavior transparent and analyzable.\n",
        "\n",
        "### **Suggested Explorations:**\n",
        "\n",
        "- **Adjust Memory Window**: Change the `memory_window` to 0, 10, or 20, and observe how the decision patterns change.\n",
        "- **Modify the Prompt**: Change the Prompt within `call_llm_for_move_decision`, for example:\n",
        "    - Make the agent more \"conservative\" or more \"risk-taking\".\n",
        "- **Collective Utility**: Modify the Prompt so that the LLM considers not only personal utility but also the impact of the move on the overall utility of both the origin and destination communities.\n",
        "- **Cost Sensitivity**: Introduce the concept of \"moving cost\" into the Prompt and observe if the LLM consequently reduces movement.\n",
        "- **Bounded Rationality**:\n",
        "    - Cognitive Discounting / Search Radius: Restrict agents to only view neighbors within a distance â‰¤ r (r=1,2) from their current block; hide all information beyond this radius.\n",
        "    - Satisficing: Add a threshold Îµ to the prompt; only allow the LLM to recommend moving if the target utility â‰¥ current utility + Îµ; otherwise, stay directly.\n",
        "\n",
        "**Note**: Large-scale calls to the LLM will incur costs. Please reasonably control `max_steps` and the call frequency during experiments.\n",
        "\n",
        "## **Enjoy your own simulation! ðŸ¥³**"
      ],
      "metadata": {
        "id": "QTVOa4ZUhnhd"
      },
      "id": "QTVOa4ZUhnhd"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}